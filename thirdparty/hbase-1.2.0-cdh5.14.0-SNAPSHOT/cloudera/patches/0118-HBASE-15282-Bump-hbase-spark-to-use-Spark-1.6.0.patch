From bac489acc23c9cdf59e66e993ddffeef100ca796 Mon Sep 17 00:00:00 2001
From: Jonathan M Hsieh <jmhsieh@apache.org>
Date: Thu, 18 Feb 2016 17:31:42 -0800
Subject: [PATCH 118/410] HBASE-15282 Bump hbase-spark to use Spark 1.6.0

Conflicts:
	hbase-spark/pom.xml

Change-Id: Ia6a06deb7e631aca641db7f3ec495a2b26055d62
---
 .../hadoop/hbase/spark/DefaultSourceSuite.scala    |    4 ++--
 1 file changed, 2 insertions(+), 2 deletions(-)

diff --git a/hbase-spark/src/test/scala/org/apache/hadoop/hbase/spark/DefaultSourceSuite.scala b/hbase-spark/src/test/scala/org/apache/hadoop/hbase/spark/DefaultSourceSuite.scala
index 30ddfc4..04dd9ba 100644
--- a/hbase-spark/src/test/scala/org/apache/hadoop/hbase/spark/DefaultSourceSuite.scala
+++ b/hbase-spark/src/test/scala/org/apache/hadoop/hbase/spark/DefaultSourceSuite.scala
@@ -20,7 +20,7 @@ package org.apache.hadoop.hbase.spark
 import org.apache.hadoop.hbase.client.{Put, ConnectionFactory}
 import org.apache.hadoop.hbase.spark.datasources.HBaseSparkConf
 import org.apache.hadoop.hbase.util.Bytes
-import org.apache.hadoop.hbase.{TableNotFoundException, TableName, HBaseTestingUtility}
+import org.apache.hadoop.hbase.{TableName, HBaseTestingUtility}
 import org.apache.spark.sql.{DataFrame, SQLContext}
 import org.apache.spark.{SparkConf, SparkContext, Logging}
 import org.scalatest.{BeforeAndAfterAll, BeforeAndAfterEach, FunSuite}
@@ -514,7 +514,7 @@ BeforeAndAfterEach with BeforeAndAfterAll with Logging {
 
 
   test("Test table that doesn't exist") {
-    intercept[TableNotFoundException] {
+    intercept[Exception] {
       df = sqlContext.load("org.apache.hadoop.hbase.spark",
         Map("hbase.columns.mapping" ->
           "KEY_FIELD STRING :key, A_FIELD STRING c:a, B_FIELD STRING c:b,",
-- 
1.7.9.5

