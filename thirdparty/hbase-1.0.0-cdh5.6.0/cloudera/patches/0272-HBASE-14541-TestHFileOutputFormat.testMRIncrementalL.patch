From 43473086fc1b085658eb4ce91dbd4c9fc933cd12 Mon Sep 17 00:00:00 2001
From: Matteo Bertozzi <matteo.bertozzi@cloudera.com>
Date: Mon, 19 Oct 2015 09:22:59 -0700
Subject: [PATCH 272/286] HBASE-14541 TestHFileOutputFormat.testMRIncrementalLoadWithSplit failed due to too many splits and few retries

Reason: flaky
Author: Matteo Bertozzi
Ref: CDH-31639

Change-Id: I12da719fc8bc31383b8243cd8447ad2b6e40808e
---
 .../hbase/mapreduce/LoadIncrementalHFiles.java     |    7 +++++-
 .../hbase/mapreduce/TestLoadIncrementalHFiles.java |   22 ++++++++++++++++++++
 2 files changed, 28 insertions(+), 1 deletions(-)

diff --git a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java
index 05ac012..73c3e72 100644
--- a/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java
+++ b/hbase-server/src/main/java/org/apache/hadoop/hbase/mapreduce/LoadIncrementalHFiles.java
@@ -362,6 +362,7 @@ public class LoadIncrementalHFiles extends Configured implements Tool {
         }
 
         int maxRetries = getConf().getInt("hbase.bulkload.retries.number", 10);
+        maxRetries = Math.max(maxRetries, startEndKeys.getFirst().length + 1);
         if (maxRetries != 0 && count >= maxRetries) {
           throw new IOException("Retry attempted " + count +
             " times without completing, bailing out");
@@ -543,7 +544,11 @@ public class LoadIncrementalHFiles extends Configured implements Tool {
 
     // We use a '_' prefix which is ignored when walking directory trees
     // above.
-    final Path tmpDir = new Path(item.hfilePath.getParent(), "_tmp");
+    final String TMP_DIR = "_tmp";
+    Path tmpDir = item.hfilePath.getParent();
+    if (!tmpDir.getName().equals(TMP_DIR)) {
+      tmpDir = new Path(tmpDir, TMP_DIR);
+    }
 
     LOG.info("HFile at " + hfilePath + " no longer fits inside a single " +
     "region. Splitting...");
diff --git a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java
index fd146c4..87d1229 100644
--- a/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java
+++ b/hbase-server/src/test/java/org/apache/hadoop/hbase/mapreduce/TestLoadIncrementalHFiles.java
@@ -189,6 +189,28 @@ public class TestLoadIncrementalHFiles {
     testRegionCrossingHFileSplit(BloomType.ROWCOL);
   }
 
+  @Test
+  public void testSplitALot() throws Exception {
+    runTest("testSplitALot", BloomType.NONE,
+      new byte[][] {
+        Bytes.toBytes("aaaa"), Bytes.toBytes("bbb"),
+        Bytes.toBytes("ccc"), Bytes.toBytes("ddd"),
+        Bytes.toBytes("eee"), Bytes.toBytes("fff"),
+        Bytes.toBytes("ggg"), Bytes.toBytes("hhh"),
+        Bytes.toBytes("iii"), Bytes.toBytes("lll"),
+        Bytes.toBytes("mmm"), Bytes.toBytes("nnn"),
+        Bytes.toBytes("ooo"), Bytes.toBytes("ppp"),
+        Bytes.toBytes("qqq"), Bytes.toBytes("rrr"),
+        Bytes.toBytes("sss"), Bytes.toBytes("ttt"),
+        Bytes.toBytes("uuu"), Bytes.toBytes("vvv"),
+        Bytes.toBytes("zzz"),
+      },
+      new byte[][][] {
+        new byte[][] { Bytes.toBytes("aaaa"), Bytes.toBytes("zzz") },
+      }
+    );
+  }
+
   private void testRegionCrossingHFileSplit(BloomType bloomType) throws Exception {
     runTest("testHFileSplit" + bloomType + "Bloom", bloomType,
         new byte[][] {
-- 
1.7.0.4

